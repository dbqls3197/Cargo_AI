{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66710712-430a-4f4c-a97d-3fc101068ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "      단계 1: 오프라인 모델 학습 (pkl 파일 생성)\n",
      "============================================================\n",
      "\n",
      "--- [오프라인 학습] 1단계: 학습 데이터 생성 시작 ---\n",
      "-> 819건의 성공 기록을 기반으로 데이터 재구성 중...\n",
      "=> 학습 데이터 생성 완료! 총 1296630개 행 생성.\n",
      "\n",
      "--- [오프라인 학습] 2단계: ML 랭킹 모델 학습 및 저장 시작 ---\n",
      "-> 전체 819개 문제 중 655개는 학습용, 164개는 검증용으로 분리.\n",
      "\n",
      "-> 모델 학습을 시작합니다 (검증용 데이터로 nDCG 점수를 모니터링합니다)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 1037332, number of used features: 3\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's ndcg@5: 0.786703\n",
      "\n",
      "--- 학습 완료 ---\n",
      "✅ 최종 검증 nDCG@5 점수: 0.7867\n",
      "=> 최고 성능의 모델을 'lgbm_ranker_model.pkl' 파일로 저장했습니다.\n",
      "\n",
      "-> 학습 과정에 따른 nDCG 점수 변화를 시각화합니다.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 234\u001b[0m\n\u001b[0;32m    232\u001b[0m training_df \u001b[38;5;241m=\u001b[39m create_training_data(cargo_data, driver_full_data, simulation_results)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m training_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlgbm_ranker_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m오류: 학습 데이터가 생성되지 않아 중단합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 152\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[1;34m(df_train, model_path)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# ★★★ 주요 수정 사항: 시각화 코드를 함수 안으로 통합했습니다. ★★★\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-> 학습 과정에 따른 nDCG 점수 변화를 시각화합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m    153\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ranker\u001b[38;5;241m.\u001b[39mevals_result_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndcg@5\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation nDCG@5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    154\u001b[0m plt\u001b[38;5;241m.\u001b[39maxvline(x\u001b[38;5;241m=\u001b[39mranker\u001b[38;5;241m.\u001b[39mbest_iteration_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Iteration (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mranker\u001b[38;5;241m.\u001b[39mbest_iteration_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 상수 및 헬퍼 함수 정의\n",
    "# ==============================================================================\n",
    "\n",
    "AVERAGE_TRUCK_SPEED_KPH = 50\n",
    "CITY_COORDS = {\n",
    "    '서울': (37.566, 126.978), '부산': (35.180, 129.075), '대구': (35.871, 128.601),\n",
    "    '인천': (37.456, 126.705), '광주': (35.160, 126.851), '대전': (36.350, 127.384),\n",
    "    '울산': (35.538, 129.311), '수원': (37.263, 127.028), '창원': (35.228, 128.681),\n",
    "    '청주': (36.642, 127.489)\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    dLat, dLon = radians(lat2 - lat1), radians(lon2 - lon1)\n",
    "    a = sin(dLat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dLon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def estimate_time_from_distance(distance_km):\n",
    "    return timedelta(hours=distance_km / AVERAGE_TRUCK_SPEED_KPH)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# A. 오프라인 학습 부분\n",
    "# ==============================================================================\n",
    "\n",
    "def create_training_data(cargo_df, driver_df, results_df):\n",
    "    print(\"\\n--- [오프라인 학습] 1단계: 학습 데이터 생성 시작 ---\")\n",
    "    training_data_rows = []\n",
    "    successful_matches = results_df[results_df['status'] == 'Matched'].copy()\n",
    "    print(f\"-> {len(successful_matches)}건의 성공 기록을 기반으로 데이터 재구성 중...\")\n",
    "\n",
    "    all_drivers = driver_df.copy()\n",
    "    all_drivers['acceptance_rate'] = (all_drivers['accepted_requests'] / all_drivers['total_requests']).fillna(0)\n",
    "\n",
    "    for index, log_row in successful_matches.iterrows():\n",
    "        query_id = f\"{index}_{log_row['request_id']}\"\n",
    "        actual_matched_driver = log_row['matched_driver']\n",
    "\n",
    "        current_cargo_series = cargo_df[cargo_df['shipper_id'] == log_row['request_id']]\n",
    "        if current_cargo_series.empty: continue\n",
    "        current_cargo = current_cargo_series.iloc[0]\n",
    "\n",
    "        # 기본 자격 필터링\n",
    "        candidate_drivers = all_drivers[all_drivers['max_load_kg'] >= float(current_cargo['weight_kg'])].copy()\n",
    "        cargo_type = current_cargo['cargo_type']\n",
    "        if cargo_type == '냉장':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == '냉장']\n",
    "        elif cargo_type == '냉동':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == '냉동']\n",
    "        # ... (다른 화물 유형 필터링 로직 추가 가능)\n",
    "        if candidate_drivers.empty: continue\n",
    "\n",
    "        # 거리 기반 후보군 축소\n",
    "        pickup_lat, pickup_lon = CITY_COORDS[current_cargo['origin']]\n",
    "        lat_diff_limit, lon_diff_limit = 2.0, 2.0  # 200km 반경\n",
    "        realistic_candidates = candidate_drivers[\n",
    "            (abs(candidate_drivers['latitude'] - pickup_lat) < lat_diff_limit) &\n",
    "            (abs(candidate_drivers['longitude'] - pickup_lon) < lon_diff_limit)\n",
    "            ].copy()\n",
    "\n",
    "        # 실제 매칭된 기사가 후보군에 포함되도록 보장\n",
    "        if actual_matched_driver not in realistic_candidates['driver_id'].values:\n",
    "            matched_driver_info = all_drivers[all_drivers['driver_id'] == actual_matched_driver]\n",
    "            realistic_candidates = pd.concat([realistic_candidates, matched_driver_info], ignore_index=True)\n",
    "\n",
    "        # 특징(Feature) 및 정답(Relevance) 생성\n",
    "        realistic_candidates['distance'] = realistic_candidates.apply(\n",
    "            lambda r: calculate_distance(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1\n",
    "        )\n",
    "        realistic_candidates['relevance'] = np.where(realistic_candidates['driver_id'] == actual_matched_driver, 2, 1)\n",
    "\n",
    "        for _, driver_row in realistic_candidates.iterrows():\n",
    "            training_data_rows.append({\n",
    "                'query_id': query_id,\n",
    "                'distance': driver_row['distance'],\n",
    "                'rating': driver_row['rating'],\n",
    "                'acceptance_rate': driver_row['acceptance_rate'],\n",
    "                'relevance': driver_row['relevance']\n",
    "            })\n",
    "\n",
    "    final_df = pd.DataFrame(training_data_rows)\n",
    "    print(f\"=> 학습 데이터 생성 완료! 총 {len(final_df)}개 행 생성.\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def train_and_save_model(df_train, model_path='lgbm_ranker_model.pkl'):\n",
    "    print(\"\\n--- [오프라인 학습] 2단계: ML 랭킹 모델 학습 및 저장 시작 ---\")\n",
    "    \n",
    "    # --- 데이터 분리 (학습용 / 검증용) ---\n",
    "    all_query_ids = df_train['query_id'].unique()\n",
    "    train_qids, val_qids = train_test_split(all_query_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_df = df_train[df_train['query_id'].isin(train_qids)]\n",
    "    val_df = df_train[df_train['query_id'].isin(val_qids)]\n",
    "    \n",
    "    print(f\"-> 전체 {len(all_query_ids)}개 문제 중 {len(train_qids)}개는 학습용, {len(val_qids)}개는 검증용으로 분리.\")\n",
    "\n",
    "    # 학습용 및 검증용 데이터 준비\n",
    "    features = ['distance', 'rating', 'acceptance_rate']\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['relevance']\n",
    "    group_train = train_df.groupby('query_id').size().to_list()\n",
    "\n",
    "    X_val = val_df[features]\n",
    "    y_val = val_df['relevance']\n",
    "    group_val = val_df.groupby('query_id').size().to_list()\n",
    "\n",
    "    # --- 모델 학습 및 평가 ---\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "    \n",
    "    print(\"\\n-> 모델 학습을 시작합니다 (검증용 데이터로 nDCG 점수를 모니터링합니다)...\")\n",
    "    \n",
    "    ranker.fit(\n",
    "        X=X_train, \n",
    "        y=y_train, \n",
    "        group=group_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_group=[group_val],\n",
    "        eval_at=[5],\n",
    "        callbacks=[lgb.early_stopping(10, verbose=True)]\n",
    "    )\n",
    "\n",
    "    # --- 최종 결과 출력 및 저장 ---\n",
    "    best_score = ranker.best_score_['valid_0']['ndcg@5']\n",
    "    print(f\"\\n--- 학습 완료 ---\")\n",
    "    print(f\"✅ 최종 검증 nDCG@5 점수: {best_score:.4f}\")\n",
    "    \n",
    "    joblib.dump(ranker, model_path)\n",
    "    print(f\"=> 최고 성능의 모델을 '{model_path}' 파일로 저장했습니다.\")\n",
    "    \n",
    "    # ★★★ 주요 수정 사항: 시각화 코드를 함수 안으로 통합했습니다. ★★★\n",
    "    print(\"\\n-> 학습 과정에 따른 nDCG 점수 변화를 시각화합니다.\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ranker.evals_result_['valid_0']['ndcg@5'], label='Validation nDCG@5')\n",
    "    plt.axvline(x=ranker.best_iteration_ - 1, color='r', linestyle='--', label=f'Best Iteration ({ranker.best_iteration_})')\n",
    "    plt.title('nDCG Score over Training Iterations')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('nDCG@5 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# B. 온라인 예측 부분\n",
    "# ==============================================================================\n",
    "\n",
    "class RealtimeMatcher:\n",
    "    def __init__(self, model_path, driver_db_path, driver_loc_path):\n",
    "        print(\"\\n--- [온라인 예측] 초기화: RealtimeMatcher 로드 시작 ---\")\n",
    "        self.ranker = joblib.load(model_path)\n",
    "\n",
    "        driver_harmful_df = pd.read_csv(driver_db_path)\n",
    "        driver_loc_df = pd.read_csv(driver_loc_path)\n",
    "        self.driver_database = pd.merge(driver_harmful_df, driver_loc_df, on='driver_id', how='left')\n",
    "        self.driver_database['acceptance_rate'] = (\n",
    "                    self.driver_database['accepted_requests'] / self.driver_database['total_requests']).fillna(0)\n",
    "        self.driver_database['next_available_time_dt'] = pd.to_datetime(datetime.now())\n",
    "        print(\"-> 드라이버 데이터베이스 로드 및 초기화 완료.\")\n",
    "\n",
    "    def recommend_top_drivers(self, new_cargo_request, top_n=5):\n",
    "        print(f\"\\n--- [온라인 예측] 요청 처리 시작: {new_cargo_request['origin']} -> {new_cargo_request['destination']} ---\")\n",
    "        request_time_dt = datetime.strptime(new_cargo_request['request_time'], '%Y-%m-%d %H:%M:%S')\n",
    "        deadline_dt = datetime.strptime(new_cargo_request['deadline'], '%Y-%m-%d %H:%M:%S')\n",
    "        pickup_lat, pickup_lon = CITY_COORDS[new_cargo_request['origin']]\n",
    "        delivery_lat, delivery_lon = CITY_COORDS[new_cargo_request['destination']]\n",
    "\n",
    "        # 1. 자격/거리/시간 필터링\n",
    "        candidates = self.driver_database.copy()\n",
    "        candidates = candidates[ㄴㄴ\n",
    "            (candidates['max_load_kg'] >= new_cargo_request['weight_kg']) &\n",
    "            (candidates['next_available_time_dt'] < deadline_dt)  # 최소한의 시간 조건\n",
    "            ]\n",
    "        candidates['distance'] = candidates.apply(\n",
    "            lambda r: calculate_distance(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1)\n",
    "        candidates = candidates[candidates['distance'] < 200].copy()  # 200km 이내\n",
    "\n",
    "        if candidates.empty:\n",
    "            print(\"-> 조건에 맞는 후보 기사를 찾을 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"-> 필터링 후 최종 {len(candidates)}명의 후보로 압축.\")\n",
    "\n",
    "        # 2. 모델 예측\n",
    "        features = ['distance', 'rating', 'acceptance_rate']\n",
    "        X_predict = candidates[features]\n",
    "        candidates['predicted_score'] = self.ranker.predict(X_predict)\n",
    "\n",
    "        # 3. 최종 결과 반환\n",
    "        final_recommendations = candidates.sort_values('predicted_score', ascending=False)\n",
    "        print(\"--- [온라인 예측] 요청 처리 완료 ---\")\n",
    "        return final_recommendations.head(top_n)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C. 전체 실행을 위한 메인 로직\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- C-1. 오프라인 학습 단계 실행 ---\n",
    "    print(\"=\" * 60)\n",
    "    print(\"      단계 1: 오프라인 모델 학습 (pkl 파일 생성)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 데이터 로드\n",
    "    cargo_data = pd.read_csv('cargo.csv')\n",
    "    driver_harmful_data = pd.read_csv('driver_harmful.csv')\n",
    "    driver_loc_data = pd.read_csv('driver_loc.csv')\n",
    "    simulation_results = pd.read_csv('simulation_results_generated.csv')\n",
    "\n",
    "    driver_full_data = pd.merge(driver_harmful_data, driver_loc_data, on='driver_id')\n",
    "\n",
    "    # 학습 데이터 생성 및 모델 학습/저장\n",
    "    training_df = create_training_data(cargo_data, driver_full_data, simulation_results)\n",
    "    if not training_df.empty:\n",
    "        train_and_save_model(training_df, model_path='lgbm_ranker_model.pkl')\n",
    "    else:\n",
    "        print(\"오류: 학습 데이터가 생성되지 않아 중단합니다.\")\n",
    "        exit()\n",
    "\n",
    "    # --- C-2. 온라인 예측 단계 테스트 실행 ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"      단계 2: 온라인 예측 시스템 테스트\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    matcher = RealtimeMatcher(\n",
    "        model_path='lgbm_ranker_model.pkl',\n",
    "        driver_db_path='driver_harmful.csv',\n",
    "        driver_loc_path='driver_loc.csv'\n",
    "    )\n",
    "\n",
    "    # 테스트용 신규 화물 요청\n",
    "    test_cargo_request = {\n",
    "        'origin': '서울', 'destination': '부산', 'weight_kg': 2000,\n",
    "        'cargo_type': '일반', 'request_time': '2025-07-15 18:00:00',\n",
    "        'deadline': '2025-07-16 12:00:00'\n",
    "    }\n",
    "\n",
    "    # 추천 기사 리스트 받기\n",
    "    top_drivers = matcher.recommend_top_drivers(test_cargo_request, top_n=5)\n",
    "\n",
    "    if top_drivers is not None:\n",
    "        print(\"\\n---  최종 추천 기사 리스트 (상위 5명) ---\")\n",
    "        print(\"=> AI 모델이 예측한, 이 화물을 가장 잘 처리할 것 같은 기사 순위입니다.\")\n",
    "        print(top_drivers[['driver_id', 'predicted_score', 'distance', 'rating', 'vehicle_type']])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"      🎉 모든 과정이 완료되었습니다.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c0b3ca-2c41-4587-a66d-3ca316648b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRanker(learning_rate=0.05, metric='ndcg', n_estimators=200,\n",
      "           objective='lambdarank', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('model/lgbm_ranker_model.pkl')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722b4a8-8f10-406f-8456-e7c382005e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8acc-92a4-49db-955c-5d5ea069f769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
