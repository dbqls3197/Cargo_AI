{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e660752-e32e-45c0-9765-e33af8fa9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 0. 필수 라이브러리 임포트\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf67193d-8f41-48f1-bac9-78f69651accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import random # 임의 선택을 위한 random 모듈 추가 (시뮬레이션에서 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ec55aa-7282-40e1-a606-205be5de7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. 상수 정의\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dff5ee3-8857-4539-9673-86d5d3741ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVERAGE_TRUCK_SPEED_KPH = 50 # 시뮬레이션 및 예측에 사용될 트럭 평균 속도 (km/h)\n",
    "CITY_COORDS = { # 주요 도시의 위도/경도 정보 (마스터 데이터)\n",
    "    '서울': (37.566, 126.978), '부산': (35.180, 129.075), '대구': (35.871, 128.601), \n",
    "    '인천': (37.456, 126.705), '광주': (35.160, 126.851), '대전': (36.350, 127.384), \n",
    "    '울산': (35.538, 129.311), '수원': (37.263, 127.028), '창원': (35.228, 128.681), \n",
    "    '청주': (36.642, 127.489)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1972c0-ea2d-4104-ad15-7b06f1c39572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. 헬퍼 함수 정의 (공통으로 사용되는 유틸리티 함수들)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4319de-205b-4555-983d-70ea55ae7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"두 위도/경도 지점 간의 거리를 킬로미터 단위로 계산합니다 (Haversine 공식).\"\"\"\n",
    "    R = 6371  # 지구 반지름 (킬로미터)\n",
    "    dLat = radians(lat2 - lat1)\n",
    "    dLon = radians(lon2 - lon1)\n",
    "    a = sin(dLat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dLon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def estimate_time_from_distance(distance_km, speed_kph=AVERAGE_TRUCK_SPEED_KPH):\n",
    "    \"\"\"거리를 기반으로 예상 운행 시간을 timedelta 객체로 반환합니다.\"\"\"\n",
    "    if distance_km < 0: return timedelta(seconds=0)\n",
    "    hours = distance_km / speed_kph\n",
    "    return timedelta(hours=hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c548cb-cfc3-41e6-904b-159184052cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# A. 오프라인 학습 부분: 모델 학습 데이터 생성 및 모델 저장\n",
    "#    (이 부분은 일반적으로 데이터 과학자/엔지니어가 모델을 학습시킬 때 한 번 실행)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0132a5dc-3a73-4484-adf5-ddf2848aa81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(cargo_df, driver_df_for_training, results_df):\n",
    "    \"\"\"\n",
    "    (필터링 강화) 각 매칭 요청에 고유 ID를 부여하여 학습 데이터를 생성합니다.\n",
    "    메모리 사용량을 줄이기 위해 성공 기록의 일부만 사용하도록 수정되었습니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [오프라인 학습] 1단계: 학습 데이터 생성 시작 ---\")\n",
    "    \n",
    "    training_data_rows = []\n",
    "    successful_matches = results_df[results_df['status'] == 'Matched'].copy()\n",
    "    \n",
    "    # 메모리 최적화를 위해 처리할 성공 기록의 수를 제한합니다. (예: 1,000개)\n",
    "    # 실제 학습 시에는 더 많은 데이터를 사용할 수 있도록 이 제한을 해제하거나 늘릴 수 있습니다.\n",
    "    if len(successful_matches) > 100:\n",
    "        successful_matches = successful_matches.head(100).copy() \n",
    "    print(f\"-> {len(successful_matches)}건의 성공 기록을 기반으로 데이터 재구성 중...\")\n",
    "\n",
    "    # create_training_data 내부에서 사용할 계산 함수 (외부 함수와 이름 충돌 방지)\n",
    "    def _calculate_distance_inner(lat1, lon1, lat2, lon2):\n",
    "        return calculate_distance(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    # 드라이버 데이터프레임 (이미 필요한 모든 정보가 병합되어 있다고 가정)\n",
    "    all_drivers = driver_df_for_training.copy() \n",
    "    \n",
    "    # acceptance_rate 계산 (컬럼 존재 확인 후)\n",
    "    if 'accepted_requests' in all_drivers.columns and 'total_requests' in all_drivers.columns:\n",
    "        all_drivers['acceptance_rate'] = all_drivers['accepted_requests'] / all_drivers['total_requests']\n",
    "        all_drivers['acceptance_rate'].fillna(0, inplace=True)\n",
    "    else:\n",
    "        print(\"경고: 'accepted_requests' 또는 'total_requests' 컬럼이 드라이버 데이터에 없습니다. acceptance_rate를 0.5로 설정합니다.\")\n",
    "        all_drivers['acceptance_rate'] = 0.5\n",
    "\n",
    "    # 각 성공 기록을 순회하며 '상대 비교' 데이터 생성\n",
    "    for index, log_row in successful_matches.iterrows():\n",
    "        query_id = f\"{index}_{log_row['request_id']}\"\n",
    "        actual_matched_driver = log_row['matched_driver']\n",
    "        \n",
    "        current_cargo_series = cargo_df[cargo_df['request_id'] == log_row['request_id']]\n",
    "        if current_cargo_series.empty: continue\n",
    "        current_cargo = current_cargo_series.iloc[0]\n",
    "\n",
    "        # 1. 기본 자격 필터링 (최대 적재량 및 화물 유형)\n",
    "        candidate_drivers = all_drivers[all_drivers['max_load_kg'] >= float(current_cargo['weight_kg'])].copy()\n",
    "        \n",
    "        if current_cargo['cargo_type'] == '냉장':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == '냉장']\n",
    "        elif current_cargo['cargo_type'] == '냉동':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == '냉동']\n",
    "        elif current_cargo['cargo_type'] == '위험물':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['hazmat_capable'] == 1]\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'].isin(['카고', '탑차', '윙바디'])]\n",
    "        elif current_cargo['cargo_type'] == '유해물질':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['harmful_substance_capable'] == 1]\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'].isin(['카고', '탑차', '윙바디'])]\n",
    "        elif current_cargo['cargo_type'] == '일반':\n",
    "            candidate_drivers = candidate_drivers[~candidate_drivers['vehicle_type'].isin(['냉장', '냉동'])]\n",
    "        \n",
    "        if candidate_drivers.empty: continue\n",
    "            \n",
    "        # 2. 거리 기반 후보군 축소\n",
    "        pickup_lat, pickup_lon = CITY_COORDS[current_cargo['origin']]\n",
    "        lat_diff_limit, lon_diff_limit = 1.0, 1.0  # 100km 반경\n",
    "        realistic_candidates = candidate_drivers[\n",
    "            (abs(candidate_drivers['latitude'] - pickup_lat) < lat_diff_limit) & \n",
    "            (abs(candidate_drivers['longitude'] - pickup_lon) < lon_diff_limit)\n",
    "        ].copy()\n",
    "        \n",
    "        if realistic_candidates.empty: realistic_candidates = candidate_drivers.copy()\n",
    "        \n",
    "        # 3. 실제 매칭된 기사가 후보군에 포함되도록 보장\n",
    "        if actual_matched_driver not in realistic_candidates['driver_id'].values:\n",
    "            matched_driver_info = all_drivers[all_drivers['driver_id'] == actual_matched_driver]\n",
    "            if not matched_driver_info.empty:\n",
    "                realistic_candidates = pd.concat([realistic_candidates, matched_driver_info], ignore_index=True)\n",
    "\n",
    "        # 4. 거리 계산 후 상위 N명만 선택\n",
    "        realistic_candidates['distance'] = realistic_candidates.apply(\n",
    "            lambda r: _calculate_distance_inner(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1\n",
    "        )\n",
    "        \n",
    "        MAX_CANDIDATES_PER_QUERY = 50\n",
    "        realistic_candidates = realistic_candidates.sort_values('distance').head(MAX_CANDIDATES_PER_QUERY)\n",
    "        \n",
    "        if actual_matched_driver not in realistic_candidates['driver_id'].values:\n",
    "            matched_driver_info = all_drivers[all_drivers['driver_id'] == actual_matched_driver]\n",
    "            if not matched_driver_info.empty:\n",
    "                matched_driver_info['distance'] = _calculate_distance_inner(\n",
    "                    matched_driver_info.iloc[0]['latitude'], matched_driver_info.iloc[0]['longitude'], \n",
    "                    pickup_lat, pickup_lon\n",
    "                )\n",
    "                if len(realistic_candidates) >= MAX_CANDIDATES_PER_QUERY:\n",
    "                    realistic_candidates = realistic_candidates.iloc[:-1]\n",
    "                realistic_candidates = pd.concat([realistic_candidates, matched_driver_info], ignore_index=True)\n",
    "\n",
    "        # 5. 정답 부여 (relevance)\n",
    "        realistic_candidates['relevance'] = np.where(\n",
    "            realistic_candidates['driver_id'] == actual_matched_driver, 2, 1\n",
    "        )\n",
    "\n",
    "        # 6. 학습 데이터 행 추가\n",
    "        for _, driver_row in realistic_candidates.iterrows():\n",
    "            training_data_rows.append({\n",
    "                'query_id': query_id,\n",
    "                'distance': driver_row['distance'],\n",
    "                'rating': driver_row['rating'],\n",
    "                'acceptance_rate': driver_row['acceptance_rate'],\n",
    "                'relevance': driver_row['relevance']\n",
    "            })\n",
    "\n",
    "    final_df = pd.DataFrame(training_data_rows)\n",
    "    \n",
    "    if not final_df.empty:\n",
    "        query_sizes = final_df.groupby('query_id').size()\n",
    "        max_query_size = query_sizes.max()\n",
    "        avg_query_size = query_sizes.mean()\n",
    "        print(f\"=> 학습 데이터 생성 완료! 총 {len(final_df)}개 행, 평균 쿼리당 {avg_query_size:.1f}개 후보\")\n",
    "        print(f\"=> 최대 쿼리 크기: {max_query_size}개 (한계: {MAX_CANDIDATES_PER_QUERY}개)\")\n",
    "    else:\n",
    "        print(\"경고: 생성된 학습 데이터가 없습니다.\")\n",
    "        \n",
    "    return final_df\n",
    "\n",
    "def train_and_save_model(df_train, model_path='lgbm_ranker_model.pkl'):\n",
    "    \"\"\"생성된 학습 데이터로 LGBMRanker 모델을 학습하고 파일로 저장합니다.\"\"\"\n",
    "    print(\"\\n--- [오프라인 학습] 2단계: ML 랭킹 모델 학습 및 저장 시작 ---\")\n",
    "    \n",
    "    features = ['distance', 'rating', 'acceptance_rate']\n",
    "    target = 'relevance'\n",
    "    query_id = 'query_id'\n",
    "\n",
    "    X_train = df_train[features]\n",
    "    y_train = df_train[target]\n",
    "    group_info = df_train.groupby(query_id).size().to_list()\n",
    "\n",
    "    ranker = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", random_state=42)\n",
    "    ranker.fit(X=X_train, y=y_train, group=group_info)\n",
    "    \n",
    "    joblib.dump(ranker, model_path)\n",
    "    print(f\"=> 학습된 모델을 '{model_path}' 파일로 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99545fd-1dc6-48a6-bc52-273e31da58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# B. 온라인 예측 부분: 실시간 매칭 요청 처리 (API 서비스에서 사용될 로직)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8464b707-6ad5-4a9b-a725-988ff5bd5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealtimeMatcher:\n",
    "    \"\"\"실시간으로 들어오는 화물 요청에 대해 최적의 기사를 추천하는 클래스.\"\"\"\n",
    "    def __init__(self, model_path, driver_db_path, driver_loc_path):\n",
    "        print(\"\\n--- [온라인 예측] 초기화: RealtimeMatcher 로드 시작 ---\")\n",
    "        self.ranker = joblib.load(model_path)\n",
    "        \n",
    "        # 드라이버 마스터 데이터 및 초기 위치 데이터 로드\n",
    "        driver_harmful_df = pd.read_csv(driver_db_path)\n",
    "        driver_loc_df = pd.read_csv(driver_loc_path)\n",
    "        self.driver_database = pd.merge(driver_harmful_df, driver_loc_df[['driver_id', 'latitude', 'longitude']], on='driver_id', how='left')\n",
    "        \n",
    "        # acceptance_rate 계산 (컬럼 존재 확인 후)\n",
    "        if 'accepted_requests' in self.driver_database.columns and 'total_requests' in self.driver_database.columns:\n",
    "            self.driver_database['acceptance_rate'] = self.driver_database['accepted_requests'] / self.driver_database['total_requests']\n",
    "            self.driver_database['acceptance_rate'].fillna(0, inplace=True)\n",
    "        else:\n",
    "            self.driver_database['acceptance_rate'] = 0.5 \n",
    "\n",
    "        # next_available_time_dt 초기화 (실제 서비스에서는 DB/실시간 시스템에서 로드)\n",
    "        # 현재 서버 시작 시간을 기준으로 모든 드라이버가 가용하다고 초기 가정\n",
    "        self.driver_database['next_available_time_dt'] = pd.to_datetime(datetime.now())\n",
    "        print(\"-> 드라이버 데이터베이스 로드 및 초기화 완료.\")\n",
    "        print(\"--- [온라인 예측] RealtimeMatcher 로드 완료 ---\")\n",
    "\n",
    "    def _calculate_distance_instance(self, lat1, lon1, lat2, lon2):\n",
    "        # 클래스 내부에서만 사용하는 calculate_distance (self 없이 호출 가능)\n",
    "        return calculate_distance(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    def _estimate_time_from_distance_instance(self, distance_km, speed_kph=AVERAGE_TRUCK_SPEED_KPH):\n",
    "        # 클래스 내부에서만 사용하는 estimate_time_from_distance (self 없이 호출 가능)\n",
    "        return estimate_time_from_distance(distance_km, speed_kph)\n",
    "\n",
    "    def recommend_top_drivers(self, new_cargo_request, top_n=10):\n",
    "        \"\"\"\n",
    "        신규 화물 요청에 대해 최적의 기사 리스트를 추천합니다.\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- [온라인 예측] 요청 처리 시작: {new_cargo_request.get('origin', '')} -> {new_cargo_request.get('destination', '')} ({new_cargo_request.get('cargo_type', '')}) ---\")\n",
    "        \n",
    "        # 입력된 request_time, deadline을 datetime 객체로 변환\n",
    "        try:\n",
    "            request_time_dt = datetime.strptime(new_cargo_request['request_time'], '%Y-%m-%d %H:%M:%S')\n",
    "            deadline_dt = datetime.strptime(new_cargo_request['deadline'], '%Y-%m-%d %H:%M:%S')\n",
    "            new_cargo_request['request_time_dt'] = request_time_dt\n",
    "            new_cargo_request['deadline_dt'] = deadline_dt\n",
    "        except ValueError:\n",
    "            print(\"오류: 잘못된 시간 형식입니다. 'YYYY-MM-DD HH:MM:SS' 형식을 사용해 주세요.\")\n",
    "            return None # 오류 발생 시 None 반환\n",
    "\n",
    "        # 0. 도시 좌표 변환\n",
    "        pickup_lat, pickup_lon = CITY_COORDS.get(new_cargo_request['origin'], (None, None))\n",
    "        delivery_lat, delivery_lon = CITY_COORDS.get(new_cargo_request['destination'], (None, None))\n",
    "\n",
    "        if pickup_lat is None or delivery_lat is None:\n",
    "            print(f\"오류: 알 수 없는 도시 이름이 포함되어 있습니다. 출발지: {new_cargo_request['origin']}, 도착지: {new_cargo_request['destination']}.\")\n",
    "            return None\n",
    "\n",
    "        # 현재 시점의 드라이버 데이터베이스 복사 (요청 처리 중 원본 데이터 오염 방지)\n",
    "        candidates = self.driver_database.copy() \n",
    "\n",
    "        # 1. 기본 자격 필터링 (최대 적재량 및 화물 유형)\n",
    "        candidates = candidates[candidates['max_load_kg'] >= float(new_cargo_request['weight_kg'])]\n",
    "        \n",
    "        cargo_type = new_cargo_request['cargo_type']\n",
    "        if cargo_type == '냉장': candidates = candidates[candidates['vehicle_type'] == '냉장']\n",
    "        elif cargo_type == '냉동': candidates = candidates[candidates['vehicle_type'] == '냉동']\n",
    "        elif cargo_type == '위험물': candidates = candidates[candidates['hazmat_capable'] == 1]\n",
    "        elif cargo_type == '유해물질': candidates = candidates[candidates['harmful_substance_capable'] == 1]\n",
    "        elif cargo_type == '일반': candidates = candidates[~candidates['vehicle_type'].isin(['냉장', '냉동'])]\n",
    "        \n",
    "        if candidates.empty: \n",
    "            print(\"-> 초기 자격 필터링 후 후보 없음.\")\n",
    "            return None\n",
    "\n",
    "        # 2. 지리적 반경 필터링으로 후보군 축소 (성능 개선)\n",
    "        lat_diff_limit_50 = 0.45 \n",
    "        lon_diff_limit_50 = 0.45\n",
    "        \n",
    "        rough_candidates = candidates[\n",
    "            (abs(candidates['latitude'] - pickup_lat) < lat_diff_limit_50) & \n",
    "            (abs(candidates['longitude'] - pickup_lon) < lon_diff_limit_50)\n",
    "        ].copy()\n",
    "        \n",
    "        if rough_candidates.empty: \n",
    "            lat_diff_limit_100 = 0.90 \n",
    "            lon_diff_limit_100 = 0.90\n",
    "            rough_candidates = candidates[\n",
    "                (abs(candidates['latitude'] - pickup_lat) < lat_diff_limit_100) & \n",
    "                (abs(candidates['longitude'] - pickup_lon) < lon_diff_limit_100)\n",
    "            ].copy()\n",
    "            if rough_candidates.empty: rough_candidates = candidates.copy() # 최후의 수단\n",
    "        \n",
    "        if rough_candidates.empty: \n",
    "            print(\"-> 거리 기반 필터링 후 후보 없음.\")\n",
    "            return None\n",
    "        \n",
    "        # 3. 축소된 'rough_candidates'에 대해서만 'distance_to_pickup' 정밀 계산\n",
    "        rough_candidates['distance'] = rough_candidates.apply(\n",
    "            lambda r: self._calculate_distance_instance(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1\n",
    "        )\n",
    "        distance_pickup_to_delivery = self._calculate_distance_instance(pickup_lat, pickup_lon, delivery_lat, delivery_lon)\n",
    "        \n",
    "        # 4. 시간 제약 필터링 (next_available_time_dt 고려)\n",
    "        rough_candidates['time_to_pickup_td'] = rough_candidates.apply(\n",
    "            lambda r: self._estimate_time_from_distance_instance(r['distance']), axis=1\n",
    "        )\n",
    "        time_pickup_to_delivery_td = self._estimate_time_from_distance_instance(distance_pickup_to_delivery)\n",
    "\n",
    "        # 각 드라이버별 유효 상차 시작 시간 = max(화물 요청 시간, 드라이버 다음 가용 시간)\n",
    "        rough_candidates['effective_pickup_start_time'] = rough_candidates.apply(\n",
    "            lambda r: max(new_cargo_request['request_time_dt'], r['next_available_time_dt']), axis=1\n",
    "        )\n",
    "        \n",
    "        # 예상 최종 도착 시간 = 유효 상차 시작 시간 + 픽업 -> 도착지 이동 시간\n",
    "        rough_candidates['estimated_delivery_time'] = rough_candidates['effective_pickup_start_time'] + time_pickup_to_delivery_td\n",
    "        \n",
    "        # 마감 시간 초과 및 가용 시간 늦은 드라이버 필터링\n",
    "        rough_candidates = rough_candidates[\n",
    "            (rough_candidates['estimated_delivery_time'] <= new_cargo_request['deadline_dt']) &\n",
    "            (rough_candidates['next_available_time_dt'] <= new_cargo_request['deadline_dt']) \n",
    "        ].copy()\n",
    "\n",
    "        if rough_candidates.empty:\n",
    "            print(\"-> 시간 제약 조건을 만족하는 후보 없음.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"-> 필터링 후 최종 {len(rough_candidates)}명의 후보로 압축.\")\n",
    "\n",
    "        # 5. 모델 예측\n",
    "        features = ['distance', 'rating', 'acceptance_rate']\n",
    "        \n",
    "        if not all(f in rough_candidates.columns for f in features):\n",
    "            print(f\"오류: 모델 예측에 필요한 피처 {features} 중 일부가 현재 후보 데이터에 없습니다. 예측 불가.\")\n",
    "            return None\n",
    "            \n",
    "        X_predict = rough_candidates[features]\n",
    "        rough_candidates['predicted_score'] = self.ranker.predict(X_predict)\n",
    "        \n",
    "        # 6. 최종 결과 반환\n",
    "        final_recommendations = rough_candidates.sort_values('predicted_score', ascending=False)\n",
    "        print(\"--- [온라인 예측] 요청 처리 완료 ---\")\n",
    "        return final_recommendations.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c97298-df25-4314-87a9-897afe357d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# C. 전체 실행을 위한 메인 로직\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992a1da5-4cb6-46f6-881f-74261d4e0f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "      단계 1: 오프라인 모델 학습 (lgbm_ranker_model.pkl 파일 생성) \n",
      "============================================================\n",
      "오류: 모델 학습을 위한 정답 데이터 'simulation_results_generated.csv' 파일을 찾을 수 없습니다.\n",
      "-> 'MatchingSimulationEngine' 클래스를 포함하는 시뮬레이션 코드를 먼저 실행하여 이 파일을 생성하세요.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'simulation_results_generated.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatchingSimulationEngine\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 클래스를 포함하는 시뮬레이션 코드를 먼저 실행하여 이 파일을 생성하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m     exit()\n\u001b[1;32m---> 40\u001b[0m simulation_results_for_training \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSIMULATION_RESULTS_FOR_TRAINING_PATH\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 학습 데이터 생성\u001b[39;00m\n\u001b[0;32m     43\u001b[0m training_dataframe \u001b[38;5;241m=\u001b[39m create_training_data(cargo_data_train, driver_data_for_training, simulation_results_for_training) \u001b[38;5;66;03m# time_df 인자 제거\u001b[39;00m\n",
      "File \u001b[1;32mc:\\aidc\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\aidc\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\aidc\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\aidc\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\aidc\\python39\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simulation_results_generated.csv'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 파일 경로 설정 (현재 작업 디렉토리에 있다고 가정)\n",
    "    CARGO_DATA_PATH = 'cargo.csv'\n",
    "    DRIVER_HARMFUL_DATA_PATH = 'driver_harmful.csv'\n",
    "    DRIVER_LOC_DATA_PATH = 'driver_loc.csv'\n",
    "    MODEL_PATH = 'lgbm_ranker_model.pkl' # 학습된 모델이 저장될/로드될 파일명\n",
    "\n",
    "    # 필요한 파일이 모두 있는지 확인 (초기 데이터 파일들)\n",
    "    required_data_files = [CARGO_DATA_PATH, DRIVER_HARMFUL_DATA_PATH, DRIVER_LOC_DATA_PATH]\n",
    "    for path in required_data_files:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"오류: 필수 데이터 파일 '{path}'을(를) 찾을 수 없습니다. 프로그램을 종료합니다.\")\n",
    "            exit()\n",
    "    \n",
    "    # --- C-1. 오프라인 학습 단계 실행 ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"      단계 1: 오프라인 모델 학습 (lgbm_ranker_model.pkl 파일 생성) \")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 학습 데이터를 만들기 위한 원본 데이터 로드\n",
    "    cargo_data_train = pd.read_csv(CARGO_DATA_PATH)\n",
    "    driver_data_harmful_train = pd.read_csv(DRIVER_HARMFUL_DATA_PATH)\n",
    "    driver_data_loc_train = pd.read_csv(DRIVER_LOC_DATA_PATH)\n",
    "\n",
    "    # 드라이버 데이터 통합 (create_training_data 함수에 전달할 데이터)\n",
    "    driver_data_for_training = pd.merge(\n",
    "        driver_data_harmful_train, \n",
    "        driver_data_loc_train[['driver_id', 'latitude', 'longitude']], \n",
    "        on='driver_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 시뮬레이션 결과 파일 로드 (모델 학습용 정답 데이터)\n",
    "    # 이 파일은 이전 시뮬레이션 엔진 코드를 통해 미리 생성되어 있어야 합니다.\n",
    "    SIMULATION_RESULTS_FOR_TRAINING_PATH = 'simulation_results_generated.csv'\n",
    "    if not os.path.exists(SIMULATION_RESULTS_FOR_TRAINING_PATH):\n",
    "        print(f\"오류: 모델 학습을 위한 정답 데이터 '{SIMULATION_RESULTS_FOR_TRAINING_PATH}' 파일을 찾을 수 없습니다.\")\n",
    "        print(\"-> 'MatchingSimulationEngine' 클래스를 포함하는 시뮬레이션 코드를 먼저 실행하여 이 파일을 생성하세요.\")\n",
    "        exit()\n",
    "    simulation_results_for_training = pd.read_csv(SIMULATION_RESULTS_FOR_TRAINING_PATH) \n",
    "\n",
    "    # 학습 데이터 생성\n",
    "    training_dataframe = create_training_data(cargo_data_train, driver_data_for_training, simulation_results_for_training) # time_df 인자 제거\n",
    "\n",
    "    # 학습 데이터가 성공적으로 생성되었다면 모델 학습 및 저장\n",
    "    if training_dataframe is not None and not training_dataframe.empty:\n",
    "        train_and_save_model(training_dataframe, model_path=MODEL_PATH)\n",
    "    else:\n",
    "        print(\"학습 데이터 생성에 실패하여 모델 학습을 중단합니다.\")\n",
    "        exit()\n",
    "    \n",
    "    # --- C-2. 온라인 예측 단계 테스트 실행 ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"      단계 2: 온라인 예측 시스템 테스트 가동\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # RealtimeMatcher 인스턴스 생성 (학습된 모델 및 드라이버 데이터 로드)\n",
    "    matcher = RealtimeMatcher(\n",
    "        model_path=MODEL_PATH,\n",
    "        driver_db_path=DRIVER_HARMFUL_DATA_PATH, # 드라이버 마스터 데이터\n",
    "        driver_loc_path=DRIVER_LOC_DATA_PATH    # 드라이버 초기 위치 데이터\n",
    "    )\n",
    "    \n",
    "    # 신규 화물 요청 예시 (실제 서비스에서 API를 통해 들어올 데이터 시뮬레이션)\n",
    "    test_cargo_request = {\n",
    "        'origin': '서울', \n",
    "        'destination': '부산', \n",
    "        'weight_kg': 2000, \n",
    "        'cargo_type': '일반',\n",
    "        'request_time': '2025-07-15 14:30:00', # 요청 발생 시간 (현재와 일치하거나 미래)\n",
    "        'deadline': '2025-07-16 10:00:00'     # 배송 마감 시간\n",
    "    }\n",
    "    \n",
    "    # 추천 기사 리스트 받기\n",
    "    print(f\"\\n[테스트 요청] {test_cargo_request['origin']} -> {test_cargo_request['destination']} ({test_cargo_request['cargo_type']}, {test_cargo_request['weight_kg']}kg)\")\n",
    "    top_drivers_recommendation = matcher.recommend_top_drivers(test_cargo_request, top_n=5) # 상위 5명 추천\n",
    "\n",
    "    if top_drivers_recommendation is not None and not top_drivers_recommendation.empty:\n",
    "        print(\"\\n--- 최종 추천 기사 리스트 (상위 5명) ---\")\n",
    "        print(\"=> 아래 기사들에게 수락 알림을 보낼 수 있습니다.\")\n",
    "        print(top_drivers_recommendation[['driver_id', 'distance', 'rating', 'predicted_score', \n",
    "                                          'vehicle_type', 'next_available_time_dt', 'estimated_delivery_time']])\n",
    "        \n",
    "        # (선택 사항) 가장 상위 드라이버의 next_available_time_dt를 업데이트하는 시뮬레이션\n",
    "        # 실제 API에서는 매칭 확정 후 데이터베이스에 반영됩니다.\n",
    "        top_driver_id_matched = top_drivers_recommendation.iloc[0]['driver_id']\n",
    "        top_driver_est_delivery_time_matched = top_drivers_recommendation.iloc[0]['estimated_delivery_time']\n",
    "        \n",
    "        # matcher 인스턴스 내부의 driver_database (메모리) 업데이트\n",
    "        # 실제 배포 시에는 이 업데이트가 영구적인 DB에 이루어져야 합니다.\n",
    "        driver_idx_to_update_actual = matcher.driver_database[matcher.driver_database['driver_id'] == top_driver_id_matched].index[0]\n",
    "        # pandas Timestamp 객체에 timedelta 더하기 (문자열 아님)\n",
    "        updated_next_available_time_actual = top_driver_est_delivery_time_matched + timedelta(hours=2)\n",
    "        matcher.driver_database.loc[driver_idx_to_update_actual, 'next_available_time_dt'] = updated_next_available_time_actual\n",
    "        print(f\"\\n[테스트 후 업데이트] 드라이버 {top_driver_id_matched}의 다음 가용 시간 (메모리 내) 업데이트: {updated_next_available_time_actual}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n--- 적합한 추천 기사를 찾을 수 없습니다. ---\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"      단계 3: 프로그램 실행 완료\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebea802-b91f-4daa-9a87-1a27daa5477a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ba680-60bf-4c34-a8da-17adebaf8342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0b1d0-e6dc-4543-8f5e-c50f567bb049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
